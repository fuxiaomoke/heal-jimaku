import os
import json
import traceback
import datetime
from typing import Optional, Any, Dict

from PyQt6.QtCore import QObject, pyqtSignal

from core.transcription_parser import TranscriptionParser
from core.srt_processor import SrtProcessor
from core.llm_api import call_llm_api_for_segmentation
from core.data_models import ParsedTranscription
from core.elevenlabs_api import ElevenLabsSTTClient
from core.soniox_api import SonioxClient, SonioxTranscriptionConfig
from config import (
    USER_LLM_API_KEY_KEY, DEFAULT_LLM_API_KEY,
    USER_LLM_API_BASE_URL_KEY, DEFAULT_LLM_API_BASE_URL,
    USER_LLM_MODEL_NAME_KEY, DEFAULT_LLM_MODEL_NAME,
    USER_LLM_TEMPERATURE_KEY, DEFAULT_LLM_TEMPERATURE,
    CLOUD_PROVIDER_ELEVENLABS_WEB, CLOUD_PROVIDER_ELEVENLABS_API, CLOUD_PROVIDER_SONIOX_API
)

class WorkerSignals(QObject):
    """å·¥ä½œçº¿ç¨‹ä¿¡å·å®šä¹‰ç±»ï¼Œç”¨äºä¸ä¸»çº¿ç¨‹é€šä¿¡"""
    finished = pyqtSignal(str, bool)
    progress = pyqtSignal(int)
    log_message = pyqtSignal(str)
    free_transcription_json_generated = pyqtSignal(str)


class ConversionWorker(QObject):
    """è½¬æ¢å·¥ä½œçº¿ç¨‹ï¼Œè´Ÿè´£åè°ƒæ•´ä¸ªè½¬æ¢æµç¨‹ï¼ŒåŒ…æ‹¬éŸ³é¢‘è½¬å½•ã€JSONè§£æã€LLMåˆ†å‰²ã€SRTç”Ÿæˆ"""

    def __init__(self,
                 input_json_path: str,
                 output_dir: str,
                 srt_processor: SrtProcessor,
                 source_format: str,
                 input_mode: str,
                 free_transcription_params: Optional[Dict[str, Any]],
                 elevenlabs_stt_client: ElevenLabsSTTClient,
                 llm_config: Dict[str, Any],
                 cloud_transcription_params: Optional[Dict[str, Any]] = None,
                 enable_ai_correction: bool = False,  # ä¸»ç•Œé¢çš„AIçº é”™è®¾ç½®
                 srt_params: Optional[Dict[str, Any]] = None,  # <--- [æ–°å¢] æ¥æ”¶ SRT å‚æ•°
                 parent: Optional[QObject] = None):
        super().__init__(parent)
        self.signals = WorkerSignals()

        self.input_json_path = input_json_path
        self.output_dir = output_dir
        self.srt_processor = srt_processor
        self.source_format = source_format
        self.input_mode = input_mode
        self.free_transcription_params = free_transcription_params
        self.cloud_transcription_params = cloud_transcription_params or {}
        self.enable_ai_correction = enable_ai_correction
        self.elevenlabs_stt_client = elevenlabs_stt_client

        self.llm_config = llm_config
        self.srt_params = srt_params  # [æ–°å¢] ä¿å­˜å‚æ•°

        # åˆå§‹åŒ–Sonioxå®¢æˆ·ç«¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
        self.soniox_client = None

        # è®¾ç½®ä¿¡å·è½¬å‘å™¨ï¼Œç”¨äºå­ç»„ä»¶ä¸ä¸»çº¿ç¨‹é€šä¿¡
        if self.srt_processor and hasattr(self.srt_processor, 'set_signals_forwarder'):
            self.srt_processor.set_signals_forwarder(self.signals)

        if self.elevenlabs_stt_client and hasattr(self.elevenlabs_stt_client, 'set_signals_forwarder'):
            self.elevenlabs_stt_client.set_signals_forwarder(self.signals)
        elif self.elevenlabs_stt_client and hasattr(self.elevenlabs_stt_client, '_signals'):
            self.elevenlabs_stt_client._signals = self.signals

        self.transcription_parser = TranscriptionParser(signals_forwarder=self.signals)
        self.is_running = True

    def stop(self):
        """åœæ­¢å½“å‰å·¥ä½œçº¿ç¨‹ï¼Œå°è¯•ä¼˜é›…åœ°ç»ˆæ­¢æ‰€æœ‰ä»»åŠ¡"""
        if not self.is_running:
            return  # é¿å…é‡å¤åœæ­¢

        self.is_running = False
        self.signals.log_message.emit("æ¥æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œå°è¯•ä¼˜é›…åœæ­¢ä»»åŠ¡...")

        # å°è¯•åœæ­¢ ElevenLabs å®¢æˆ·ç«¯
        if self.elevenlabs_stt_client and hasattr(self.elevenlabs_stt_client, 'stop_current_task'):
            try:
                self.elevenlabs_stt_client.stop_current_task()
                self.signals.log_message.emit("å·²å‘ ElevenLabs å‘é€åœæ­¢ä¿¡å·")
            except Exception as e:
                self.signals.log_message.emit(f"åœæ­¢ ElevenLabs ä»»åŠ¡æ—¶å‘ç”Ÿé”™è¯¯: {e}")

        # å°è¯•åœæ­¢ Soniox å®¢æˆ·ç«¯
        if self.soniox_client and hasattr(self.soniox_client, 'stop_current_task'):
            try:
                self.soniox_client.stop_current_task()
                self.signals.log_message.emit("å·²å‘ Soniox å‘é€åœæ­¢ä¿¡å·")
            except Exception as e:
                self.signals.log_message.emit(f"åœæ­¢ Soniox ä»»åŠ¡æ—¶å‘ç”Ÿé”™è¯¯: {e}")

        # ç«‹å³å‘é€å®Œæˆä¿¡å·ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡
        # ç¡®ä¿ä¸»çº¿ç¨‹çŸ¥é“æˆ‘ä»¬å·²ç»åœæ­¢
        self.signals.finished.emit("ä»»åŠ¡å·²åœæ­¢", False)

    def run(self):
        """æ‰§è¡Œä¸»è½¬æ¢æµç¨‹ï¼Œå¤„ç†éŸ³é¢‘è½¬å½•ã€JSONè§£æã€LLMåˆ†å‰²å’ŒSRTç”Ÿæˆ"""
        try:
            generated_json_path = self.input_json_path
            actual_source_format = self.source_format
            current_overall_progress = 0

            # å®šä¹‰å„é˜¶æ®µè¿›åº¦æ¯”ä¾‹
            PROGRESS_INIT = 5
            PROGRESS_STT_COMPLETE_FREE = 35
            PROGRESS_JSON_SAVED_FREE = 38
            PROGRESS_JSON_PARSED_FREE = 40
            PROGRESS_LLM_COMPLETE_FREE = 70
            PROGRESS_JSON_PARSED_LOCAL = 10
            PROGRESS_LLM_COMPLETE_LOCAL = 40
            PROGRESS_SRT_PROCESSING_MAX = 99
            PROGRESS_FINAL = 100

            self.signals.progress.emit(PROGRESS_INIT)
            current_overall_progress = PROGRESS_INIT

            # === [æ–°å¢] æ ¸å¿ƒä¿®å¤ï¼šåœ¨ä»»åŠ¡å¼€å§‹æ—¶ï¼Œå¼ºåˆ¶æ›´æ–° SRT å¤„ç†å™¨çš„å‚æ•° ===
            if self.srt_processor:
                # 1. åŒæ­¥ SRT åŸºç¡€å‚æ•°
                if self.srt_params:
                    self.signals.log_message.emit("æ­£åœ¨åŒæ­¥ SRT å‚æ•°åˆ°å¤„ç†å™¨...")
                    self.srt_processor.update_srt_params(self.srt_params)

                # 2. åŒæ­¥ LLM å‚æ•° (ç¡®ä¿ Processor ä¸­çš„ AI çº é”™åŠŸèƒ½ä½¿ç”¨æ­£ç¡®çš„ Key)
                if self.llm_config:
                    self.srt_processor.update_llm_config(
                        api_key=self.llm_config.get("user_llm_api_key"),
                        base_url=self.llm_config.get("user_llm_api_base_url"),
                        model=self.llm_config.get("user_llm_model_name"),
                        temperature=self.llm_config.get("user_llm_temperature")
                    )

            # å…è´¹è½¬å½•æ¨¡å¼ï¼šä½¿ç”¨ElevenLabs Web APIè¿›è¡ŒéŸ³é¢‘è½¬å½•
            if self.input_mode == "free_transcription":
                if not self.free_transcription_params or not self.free_transcription_params.get("audio_file_path"):
                    self.signals.finished.emit("é”™è¯¯ï¼šå…è´¹è½¬å½•æ¨¡å¼ä¸‹æœªæä¾›éŸ³é¢‘æ–‡ä»¶å‚æ•°ã€‚", False); return

                self.signals.log_message.emit("--- å¼€å§‹å…è´¹åœ¨çº¿è½¬å½• (ElevenLabs Web) ---")
                audio_path = self.free_transcription_params["audio_file_path"]
                lang_from_dialog = self.free_transcription_params.get("language")
                num_speakers = self.free_transcription_params.get("num_speakers")
                tag_events = self.free_transcription_params.get("tag_audio_events", True)
                model_id = self.free_transcription_params.get("elevenlabs_web_model", "scribe_v2")  # è·å–æ¨¡å‹ID

                transcription_data = self.elevenlabs_stt_client.transcribe_audio(
                    audio_file_path=audio_path, language_code=lang_from_dialog,
                    num_speakers=num_speakers, tag_audio_events=tag_events,
                    model_id=model_id  # ä¼ é€’æ¨¡å‹ID
                )
                if not self.is_running: self.signals.finished.emit("ä»»åŠ¡åœ¨ElevenLabs Web APIè°ƒç”¨åè¢«å–æ¶ˆã€‚", False); return
                if transcription_data is None: self.signals.finished.emit("ElevenLabs Web API è½¬å½•å¤±è´¥æˆ–è¿”å›ç©ºã€‚", False); return

                current_overall_progress = PROGRESS_STT_COMPLETE_FREE
                self.signals.progress.emit(current_overall_progress)

                # ä¿å­˜è½¬å½•ç»“æœä¸ºJSONæ–‡ä»¶
                base_name = os.path.splitext(os.path.basename(audio_path))[0]
                generated_json_path = os.path.join(self.output_dir, f"{base_name}_elevenlabs_web_transcript.json")
                try:
                    with open(generated_json_path, "w", encoding="utf-8") as f_json:
                        json.dump(transcription_data, f_json, ensure_ascii=False, indent=4)
                    self.signals.log_message.emit(f"ElevenLabs Webè½¬å½•ç»“æœå·²ä¿å­˜åˆ°: {generated_json_path}")
                    self.signals.free_transcription_json_generated.emit(generated_json_path)
                except IOError as e:
                    self.signals.finished.emit(f"ä¿å­˜ElevenLabsè½¬å½•JSONå¤±è´¥: {e}", False); return
                actual_source_format = "elevenlabs"
                self.signals.log_message.emit("--- å…è´¹åœ¨çº¿è½¬å½•ä¸JSONä¿å­˜å®Œæˆ ---")

                current_overall_progress = PROGRESS_JSON_SAVED_FREE
                self.signals.progress.emit(current_overall_progress)

            # äº‘ç«¯è½¬å½•æ¨¡å¼ï¼šæ”¯æŒå¤šç§æœåŠ¡å•†
            elif self.input_mode == "cloud_transcription":
                if not self.cloud_transcription_params or not self.cloud_transcription_params.get("audio_file_path"):
                    self.signals.finished.emit("é”™è¯¯ï¼šäº‘ç«¯è½¬å½•æ¨¡å¼ä¸‹æœªæä¾›éŸ³é¢‘æ–‡ä»¶å‚æ•°ã€‚", False); return

                audio_path = self.cloud_transcription_params["audio_file_path"]
                provider = self.cloud_transcription_params.get("provider", CLOUD_PROVIDER_ELEVENLABS_WEB)

                self.signals.log_message.emit(f"--- å¼€å§‹äº‘ç«¯è½¬å½• ({provider}) ---")
                transcription_data = None
                actual_source_format = None

                try:
                    if provider == CLOUD_PROVIDER_ELEVENLABS_WEB:
                        # ä½¿ç”¨ç°æœ‰çš„ElevenLabs Webå®¢æˆ·ç«¯
                        self.signals.log_message.emit("ä½¿ç”¨ElevenLabs (Web/Free) æœåŠ¡")
                        lang_from_dialog = self.cloud_transcription_params.get("language", "auto")
                        num_speakers = self.cloud_transcription_params.get("num_speakers", 0)
                        tag_events = self.cloud_transcription_params.get("tag_audio_events", True)
                        model_id = self.cloud_transcription_params.get("elevenlabs_web_model", "scribe_v2")  # è·å–æ¨¡å‹ID

                        transcription_data = self.elevenlabs_stt_client.transcribe_audio(
                            audio_file_path=audio_path, language_code=lang_from_dialog,
                            num_speakers=num_speakers, tag_audio_events=tag_events,
                            model_id=model_id  # ä¼ é€’æ¨¡å‹ID
                        )
                        actual_source_format = "elevenlabs"

                    elif provider == CLOUD_PROVIDER_ELEVENLABS_API:
                        # ä½¿ç”¨ElevenLabså®˜æ–¹API
                        self.signals.log_message.emit("ä½¿ç”¨ElevenLabs (API/Paid) æœåŠ¡")
                        
                        api_key = self.cloud_transcription_params.get("elevenlabs_api_key")
                        if not api_key:
                            api_key = self.cloud_transcription_params.get("api_key")
                        
                        if not api_key:
                            self.signals.finished.emit("é”™è¯¯ï¼šElevenLabs APIæ¨¡å¼éœ€è¦APIå¯†é’¥ã€‚", False); return

                        lang_from_dialog = self.cloud_transcription_params.get("elevenlabs_api_language", "auto")
                        num_speakers = self.cloud_transcription_params.get("elevenlabs_api_num_speakers", 0)
                        enable_diarization = self.cloud_transcription_params.get("elevenlabs_api_enable_diarization", False)
                        tag_events = self.cloud_transcription_params.get("elevenlabs_api_tag_audio_events", False)
                        model_id = self.cloud_transcription_params.get("elevenlabs_api_model", "scribe_v2")  # è·å–æ¨¡å‹ID

                        transcription_data = self.elevenlabs_stt_client.transcribe_audio_official_api(
                            audio_file_path=audio_path, api_key=api_key,
                            language_code=lang_from_dialog, num_speakers=num_speakers,
                            enable_diarization=enable_diarization, tag_audio_events=tag_events,
                            model_id=model_id  # ä¼ é€’æ¨¡å‹ID
                        )
                        actual_source_format = "elevenlabs_api"

                    elif provider == CLOUD_PROVIDER_SONIOX_API:
                        # ä½¿ç”¨Soniox API
                        self.signals.log_message.emit("ä½¿ç”¨Soniox (API/Paid) æœåŠ¡")
                        
                        api_key = self.cloud_transcription_params.get("soniox_api_key")
                        if not api_key:
                            api_key = self.cloud_transcription_params.get("api_key")
                            
                        if not api_key:
                            self.signals.finished.emit("é”™è¯¯ï¼šSoniox APIæ¨¡å¼éœ€è¦APIå¯†é’¥ã€‚", False); return

                        # åˆå§‹åŒ–Sonioxå®¢æˆ·ç«¯
                        self.soniox_client = SonioxClient(signals_forwarder=self.signals)

                        # è·å–é…ç½®å‚æ•°
                        language_hints = self.cloud_transcription_params.get("soniox_language_hints", [])
                        enable_speaker_diarization = self.cloud_transcription_params.get("soniox_enable_speaker_diarization", False)
                        enable_language_identification = self.cloud_transcription_params.get("soniox_enable_language_identification", True)
                        # æ³¨æ„ï¼šAIæ ¡å¯¹è®¾ç½®å·²åºŸå¼ƒï¼Œä½¿ç”¨ä¸»ç•Œé¢çš„ç»Ÿä¸€è®¾ç½®

                        context_terms = self.cloud_transcription_params.get("soniox_context_terms", [])
                        if isinstance(context_terms, str):
                            context_terms = [term.strip() for term in context_terms.split('\n') if term.strip()]
                            
                        context_text = self.cloud_transcription_params.get("soniox_context_text", "")
                        context_general = self.cloud_transcription_params.get("soniox_context_general", [])

                        self.signals.log_message.emit(f"Sonioxé…ç½®: è¯­è¨€æç¤º={language_hints}, è¯´è¯äººåˆ†ç¦»={enable_speaker_diarization}, AIæ ¡æ­£=ä½¿ç”¨ä¸»ç•Œé¢è®¾ç½®")

                        soniox_config = SonioxTranscriptionConfig(
                            api_key=api_key,
                            language_hints=language_hints,
                            enable_speaker_diarization=enable_speaker_diarization,
                            enable_language_identification=enable_language_identification,
                            context_terms=context_terms,
                            context_text=context_text,
                            context_general=context_general
                        )

                        transcription_data = self.soniox_client.transcribe_audio_file(audio_path, soniox_config)
                        actual_source_format = "soniox"

                    else:
                        self.signals.finished.emit(f"é”™è¯¯ï¼šä¸æ”¯æŒçš„æœåŠ¡å•† '{provider}'", False); return

                    # æ£€æŸ¥è½¬å½•ç»“æœ
                    if not self.is_running:
                        self.signals.finished.emit("ä»»åŠ¡åœ¨äº‘ç«¯è½¬å½•APIè°ƒç”¨åè¢«å–æ¶ˆã€‚", False); return

                    if transcription_data is None:
                        provider_name = provider.replace("_api", "").replace("_web", "").upper()
                        self.signals.finished.emit(f"{provider_name}è½¬å½•å¤±è´¥æˆ–è¿”å›ç©ºã€‚", False); return

                    current_overall_progress = PROGRESS_STT_COMPLETE_FREE
                    self.signals.progress.emit(current_overall_progress)

                    # ä¿å­˜è½¬å½•ç»“æœä¸ºJSONæ–‡ä»¶
                    base_name = os.path.splitext(os.path.basename(audio_path))[0]
                    provider_suffix = provider.replace("_api", "").replace("_web", "")
                    generated_json_path = os.path.join(self.output_dir, f"{base_name}_{provider_suffix}_transcript.json")

                    try:
                        with open(generated_json_path, "w", encoding="utf-8") as f_json:
                            json.dump(transcription_data, f_json, ensure_ascii=False, indent=4)
                        self.signals.log_message.emit(f"{provider.upper()}è½¬å½•ç»“æœå·²ä¿å­˜åˆ°: {generated_json_path}")
                        self.signals.free_transcription_json_generated.emit(generated_json_path)
                    except IOError as e:
                        self.signals.finished.emit(f"ä¿å­˜{provider.upper()}è½¬å½•JSONå¤±è´¥: {e}", False); return

                    # === ä¿®æ”¹å¼€å§‹ï¼šåœ¨ä¿å­˜ JSON æˆåŠŸåï¼Œæ‰§è¡Œæ¸…ç† ===
                    if provider == CLOUD_PROVIDER_SONIOX_API and transcription_data and "soniox_metadata" in transcription_data:
                        self.signals.log_message.emit("æ­£åœ¨æ¸…ç† Soniox äº‘ç«¯æ•°æ®ä»¥ä¿æŠ¤éšç§...")
                        metadata = transcription_data["soniox_metadata"]

                        # è·å– ID
                        file_id = metadata.get("file_id")
                        trans_id = metadata.get("transcription_id")

                        # æ‰§è¡Œåˆ é™¤
                        if file_id:
                            self.soniox_client.delete_file(file_id, api_key)
                        if trans_id:
                            self.soniox_client.delete_transcription(trans_id, api_key)

                        self.signals.log_message.emit("Soniox äº‘ç«¯æ•°æ®æ¸…ç†å®Œæ¯•")

                    elif provider == CLOUD_PROVIDER_ELEVENLABS_API and transcription_data:
                        # å°è¯•è·å– transcription_id
                        transcription_id = transcription_data.get("transcription_id")

                        if transcription_id:
                            self.signals.log_message.emit(f"æ­£åœ¨æ¸…ç† ElevenLabs äº‘ç«¯æ•°æ® (ID: {transcription_id})...")

                            # è·å–ç”¨äºè½¬å½•çš„ API Key
                            api_key_used = self.cloud_transcription_params.get("elevenlabs_api_key")

                            if api_key_used:
                                # æ‰§è¡Œåˆ é™¤
                                success = self.elevenlabs_stt_client.delete_transcription(transcription_id, api_key_used)

                                if success:
                                    self.signals.log_message.emit("âœ… ElevenLabs äº‘ç«¯éšç§æ•°æ®æ¸…ç†å®Œæ¯•")
                                else:
                                    self.signals.log_message.emit("âš ï¸ ElevenLabs äº‘ç«¯æ•°æ®åˆ é™¤å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥")
                            else:
                                self.signals.log_message.emit("âš ï¸ æœªæ‰¾åˆ° API Keyï¼Œæ— æ³•æ‰§è¡Œ ElevenLabs åˆ é™¤æ“ä½œ")
                        else:
                            self.signals.log_message.emit("âš ï¸ æœªæ‰¾åˆ° ElevenLabs è½¬å½• IDï¼Œè·³è¿‡äº‘ç«¯æ¸…ç†")

                    # === ä¿®æ”¹ç»“æŸ ===

                    self.signals.log_message.emit(f"--- äº‘ç«¯è½¬å½• ({provider}) å®Œæˆ ---")
                    current_overall_progress = PROGRESS_JSON_SAVED_FREE
                    self.signals.progress.emit(current_overall_progress)

                except Exception as e:
                    provider_name = provider.replace("_api", "").replace("_web", "").upper()
                    self.signals.finished.emit(f"{provider_name}è½¬å½•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}", False); return
            else:
                self.signals.log_message.emit(f"ä½¿ç”¨æœ¬åœ°JSONæ–‡ä»¶: {os.path.basename(generated_json_path)}")

            if not self.is_running: self.signals.finished.emit("ä»»åŠ¡åœ¨åŠ è½½/ç”ŸæˆJSONå‰è¢«å–æ¶ˆã€‚", False); return

            # è§£æJSONè½¬å½•æ•°æ®
            self.signals.log_message.emit(f"å¼€å§‹è§£æJSONæ–‡ä»¶ '{os.path.basename(generated_json_path)}', æ ¼å¼ '{actual_source_format}'")
            try:
                with open(generated_json_path, "r", encoding="utf-8") as f: raw_api_data = json.load(f)
            except FileNotFoundError:
                self.signals.finished.emit(f"é”™è¯¯ï¼šæ— æ³•æ‰¾åˆ°è¾“å…¥JSONæ–‡ä»¶ '{generated_json_path}'ã€‚", False); return
            except json.JSONDecodeError as e:
                self.signals.finished.emit(f"é”™è¯¯ï¼šè§£æJSONæ–‡ä»¶ '{generated_json_path}' å¤±è´¥: {e}", False); return

            parsed_transcription_data: Optional[ParsedTranscription] = self.transcription_parser.parse(raw_api_data, actual_source_format)
            
            if parsed_transcription_data is None:
                self.signals.finished.emit(f"JSON è§£æå¤±è´¥ ({actual_source_format} æ ¼å¼)ã€‚è¯·æ£€æŸ¥æ—¥å¿—ä¸­çš„å…·ä½“é”™è¯¯ã€‚", False); return

            if self.input_mode == "local_json":
                current_overall_progress = PROGRESS_JSON_PARSED_LOCAL
            else:
                current_overall_progress = PROGRESS_JSON_PARSED_FREE
            self.signals.progress.emit(current_overall_progress)

            # å‡†å¤‡LLMåˆ†å‰²æ–‡æœ¬
            text_to_segment = parsed_transcription_data.full_text
            
            # å¤„ç†ç©ºæ–‡æœ¬æƒ…å†µ
            if not text_to_segment:
                if parsed_transcription_data.words:
                    text_to_segment = " ".join([word.text for word in parsed_transcription_data.words if word.text is not None])
                
                if not text_to_segment: 
                    self.signals.log_message.emit("è­¦å‘Š: è½¬å½•ç»“æœä¸­æœªå‘ç°æœ‰æ•ˆæ–‡æœ¬ã€‚å¯èƒ½æ˜¯é™éŸ³éŸ³é¢‘æˆ–è½¬å½•æœªå®Œå…¨æˆåŠŸã€‚")
                    # ç”Ÿæˆä¸€ä¸ªç©ºçš„SRTæ–‡ä»¶ä»¥ç¤ºå®Œæˆï¼Œè€Œä¸æ˜¯æŠ¥é”™
                    output_base_name = os.path.splitext(os.path.basename(generated_json_path))[0]
                    output_srt_filepath = os.path.join(self.output_dir, f"{output_base_name}.srt")
                    with open(output_srt_filepath, "w", encoding="utf-8") as f: f.write("")
                    self.signals.finished.emit(f"è½¬æ¢å®Œæˆï¼ˆå†…å®¹ä¸ºç©ºï¼‰ã€‚SRT æ–‡ä»¶å·²ä¿å­˜åˆ°:\n{output_srt_filepath}", True)
                    return

            self.signals.log_message.emit(f"è·å–åˆ°å¾…åˆ†å‰²æ–‡æœ¬ï¼Œé•¿åº¦: {len(text_to_segment)} å­—ç¬¦ã€‚")
            if not self.is_running: self.signals.finished.emit("ä»»åŠ¡åœ¨è§£æJSONåè¢«å–æ¶ˆã€‚", False); return

            # ç¡®å®šLLMå¤„ç†çš„ç›®æ ‡è¯­è¨€
            llm_target_language_for_api: Optional[str] = None
            if self.input_mode == "free_transcription" and self.free_transcription_params:
                lang_code_from_dialog = self.free_transcription_params.get("language")
                if lang_code_from_dialog and lang_code_from_dialog != "auto":
                    llm_target_language_for_api = lang_code_from_dialog
                    self.signals.log_message.emit(f"LLMå¤„ç†å°†ä¼˜å…ˆä½¿ç”¨å¯¹è¯æ¡†æŒ‡å®šçš„è¯­è¨€: {llm_target_language_for_api}")

            if not llm_target_language_for_api and parsed_transcription_data and \
               parsed_transcription_data.language_code:
                asr_lang_code = parsed_transcription_data.language_code.lower()
                mapped_lang = None
                if asr_lang_code.startswith('zh'): mapped_lang = 'zh'
                elif asr_lang_code == 'ja' or asr_lang_code == 'jpn': mapped_lang = 'ja'
                elif asr_lang_code == 'en' or asr_lang_code.startswith('en-') or asr_lang_code == 'eng': mapped_lang = 'en'
                elif asr_lang_code == 'ko': mapped_lang = 'ko'

                if mapped_lang:
                    llm_target_language_for_api = mapped_lang
                    self.signals.log_message.emit(f"LLMå¤„ç†å°†ä½¿ç”¨ASRæ£€æµ‹åˆ°çš„è¯­è¨€: {llm_target_language_for_api} (åŸå§‹ASRä»£ç : '{asr_lang_code}')")
                else:
                    self.signals.log_message.emit(f"ASRè¯­è¨€ä»£ç  '{asr_lang_code}' æœªèƒ½æ˜ å°„åˆ°ç›®æ ‡è¯­è¨€ (ä¸­/æ—¥/è‹±/éŸ©)ï¼ŒLLMå°†è¿›è¡Œè‡ªåŠ¨è¯­è¨€æ£€æµ‹ã€‚")
            elif not llm_target_language_for_api:
                 self.signals.log_message.emit(f"æœªä»å¯¹è¯æ¡†æˆ–ASRç»“æœä¸­è·å¾—æ˜ç¡®è¯­è¨€æŒ‡ç¤ºï¼ŒLLMå°†è¿›è¡Œè‡ªåŠ¨è¯­è¨€æ£€æµ‹ã€‚")

            # è·å–LLM APIé…ç½®å‚æ•°
            llm_api_key = self.llm_config.get(USER_LLM_API_KEY_KEY, DEFAULT_LLM_API_KEY)
            llm_base_url_str = self.llm_config.get(USER_LLM_API_BASE_URL_KEY, DEFAULT_LLM_API_BASE_URL)
            llm_model_name = self.llm_config.get(USER_LLM_MODEL_NAME_KEY, DEFAULT_LLM_MODEL_NAME)
            llm_temperature = self.llm_config.get(USER_LLM_TEMPERATURE_KEY, DEFAULT_LLM_TEMPERATURE)

            # è·å–APIæ ¼å¼é…ç½®
            import config as app_config
            current_profile = app_config.get_current_llm_profile(self.llm_config)
            llm_api_format = current_profile.get("api_format", app_config.API_FORMAT_AUTO)

            # è°ƒç”¨LLM APIè¿›è¡Œæ–‡æœ¬åˆ†å‰²
            self.signals.log_message.emit(f"è°ƒç”¨LLM APIè¿›è¡Œæ–‡æœ¬åˆ†å‰² (URLé…ç½®: '{llm_base_url_str}', æ¨¡å‹: '{llm_model_name}', æ¸©åº¦: {llm_temperature}, APIæ ¼å¼: {llm_api_format})...")
            llm_segments = call_llm_api_for_segmentation(
                api_key=llm_api_key,
                text_to_segment=text_to_segment,
                custom_api_base_url_str=llm_base_url_str,
                custom_model_name=llm_model_name,
                custom_temperature=llm_temperature,
                signals_forwarder=self.signals,
                target_language=llm_target_language_for_api,
                api_format=llm_api_format  # ä¼ é€’APIæ ¼å¼å‚æ•°
            )
            if not self.is_running : self.signals.finished.emit("ä»»åŠ¡åœ¨LLM APIè°ƒç”¨æœŸé—´è¢«å–æ¶ˆã€‚", False); return
            if llm_segments is None: self.signals.finished.emit("LLM API è°ƒç”¨å¤±è´¥æˆ–è¿”å›ç©ºã€‚", False); return

            if self.input_mode == "free_transcription":
                current_overall_progress = PROGRESS_LLM_COMPLETE_FREE
            else:
                current_overall_progress = PROGRESS_LLM_COMPLETE_LOCAL
            self.signals.progress.emit(current_overall_progress)

            # ç”ŸæˆSRTå­—å¹•å†…å®¹
            self.signals.log_message.emit("å¼€å§‹ä½¿ç”¨LLMè¿”å›çš„ç‰‡æ®µç”Ÿæˆ SRT å†…å®¹...")

            srt_progress_offset = current_overall_progress
            srt_progress_range = PROGRESS_SRT_PROCESSING_MAX - srt_progress_offset
            self.signals.log_message.emit(f"SRTå¤„ç†é˜¶æ®µ - å…¨å±€è¿›åº¦åç§»: {srt_progress_offset}%, èŒƒå›´: {srt_progress_range}%")

            # è®¾ç½®SRTå¤„ç†å™¨çš„è¿›åº¦å‚æ•°
            if self.srt_processor:
                self.srt_processor._current_progress_offset = srt_progress_offset
                self.srt_processor._current_progress_range = srt_progress_range

            # è·å–AIæ ¡æ­£å¼€å…³ï¼ˆä»…åœ¨Sonioxæ¨¡å¼æ—¶ä½¿ç”¨ï¼‰
            enable_ai_correction = False
            if actual_source_format == "soniox":
                # ç»Ÿä¸€ä½¿ç”¨ä¸»ç•Œé¢çš„AIæ ¡å¯¹è®¾ç½®ï¼ˆé€‚ç”¨äºæœ¬åœ°JSONå’Œäº‘ç«¯è½¬å½•ï¼‰
                enable_ai_correction = self.enable_ai_correction

            final_srt, correction_hints = self.srt_processor.process_to_srt(
                parsed_transcription_data, llm_segments, actual_source_format, enable_ai_correction=enable_ai_correction
            )

            if not self.is_running: self.signals.finished.emit("ä»»åŠ¡åœ¨SRTç”ŸæˆæœŸé—´è¢«å–æ¶ˆã€‚", False); return
            if final_srt is None: self.signals.finished.emit("SRT å†…å®¹ç”Ÿæˆå¤±è´¥ã€‚", False); return

            # ä¿å­˜æœ€ç»ˆSRTæ–‡ä»¶
            if self.input_mode == "local_json":
                output_base_name = os.path.splitext(os.path.basename(generated_json_path))[0]
            elif self.input_mode == "free_transcription" and self.free_transcription_params and self.free_transcription_params.get("audio_file_path"):
                output_base_name = os.path.splitext(os.path.basename(self.free_transcription_params["audio_file_path"]))[0]
                if output_base_name.endswith("_elevenlabs_transcript"):
                    output_base_name = output_base_name[:-len("_elevenlabs_transcript")]
            elif self.input_mode == "cloud_transcription" and self.cloud_transcription_params:
                # äº‘ç«¯è½¬å½•æ¨¡å¼ï¼šæ ¹æ®éŸ³é¢‘æ–‡ä»¶åç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
                if self.cloud_transcription_params.get("audio_file_path"):
                    output_base_name = os.path.splitext(os.path.basename(self.cloud_transcription_params["audio_file_path"]))[0]
                elif self.cloud_transcription_params.get("audio_files") and len(self.cloud_transcription_params["audio_files"]) > 0:
                    # æ‰¹é‡å¤„ç†æƒ…å†µï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡ä»¶å
                    output_base_name = os.path.splitext(os.path.basename(self.cloud_transcription_params["audio_files"][0]))[0]
                else:
                    output_base_name = "processed_subtitle"
            else:
                output_base_name = "processed_subtitle"

            output_srt_filepath = os.path.join(self.output_dir, f"{output_base_name}.srt")
            try:
                with open(output_srt_filepath, "w", encoding="utf-8") as f: f.write(final_srt)
                self.signals.log_message.emit(f"SRT æ–‡ä»¶å·²æˆåŠŸä¿å­˜åˆ°: {output_srt_filepath}")
            except IOError as e:
                self.signals.finished.emit(f"ä¿å­˜æœ€ç»ˆSRTæ–‡ä»¶å¤±è´¥: {e}", False); return

            # ä¿å­˜æ ¡å¯¹æç¤ºæ–‡ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰
            if correction_hints:
                # ä¿®æ”¹æ–‡ä»¶åæ ¼å¼ï¼šæ ¡å¯¹æç¤ºæŠ¥å‘Š + åŸæ–‡ä»¶å + .txt
                correction_hints_filename = f"æ ¡å¯¹æç¤ºæŠ¥å‘Š{output_base_name}.txt"
                correction_hints_filepath = os.path.join(self.output_dir, correction_hints_filename)
                self.signals.log_message.emit(f"æ­£åœ¨ç”Ÿæˆæ ¡å¯¹æŠ¥å‘Š...")
                try:
                    with open(correction_hints_filepath, "w", encoding="utf-8") as f:
                        f.write("Heal-Jimaku æ ¡å¯¹æç¤ºæŠ¥å‘Š\n")
                        f.write("=" * 50 + "\n\n")
                        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                        f.write(f"æºæ ¼å¼: {actual_source_format}\n")
                        # åˆ†ç¦»ä¼ ç»Ÿä½ç½®ä¿¡åº¦æç¤ºå’ŒAIæ ¡å¯¹æŠ¥å‘Š
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«AIæ ¡å¯¹æŠ¥å‘Š
                        has_ai_report = any("ğŸ¯ AIæ ¡å¯¹æŠ¥å‘Š" in h for h in correction_hints)

                        if has_ai_report:
                            # å¦‚æœæœ‰AIæŠ¥å‘Šï¼Œä¼ ç»Ÿæç¤ºå°±åœ¨AIæŠ¥å‘Šä¹‹å‰
                            ai_report_start = None
                            for i, h in enumerate(correction_hints):
                                if "ğŸ¯ AIæ ¡å¯¹æŠ¥å‘Š" in h:
                                    ai_report_start = i
                                    break

                            traditional_hints = correction_hints[:ai_report_start] if ai_report_start is not None else correction_hints
                        else:
                            # æ²¡æœ‰AIæŠ¥å‘Šï¼Œå…¨éƒ¨éƒ½æ˜¯ä¼ ç»Ÿæç¤º
                            traditional_hints = correction_hints

                        # è®¡ç®—ä¼ ç»Ÿä½ç½®ä¿¡åº¦ç‰‡æ®µæ•°é‡ï¼ˆæ¯4è¡Œä¸ºä¸€ä¸ªç‰‡æ®µï¼‰
                        traditional_segments_count = len([h for h in traditional_hints if h.startswith("ä½ç½®ä¿¡åº¦è¯æ±‡:")])

                        f.write(f"ä½ç½®ä¿¡åº¦ç‰‡æ®µæ•°é‡: {traditional_segments_count}\n\n")
                        f.write("ä»¥ä¸‹æ˜¯æ ¹æ®ç½®ä¿¡åº¦åˆ†æç”Ÿæˆçš„æ ¡å¯¹å»ºè®®ï¼š\n")
                        f.write("-" * 50 + "\n\n")
                        f.write("\n".join(correction_hints))

                    self.signals.log_message.emit(f"æ ¡å¯¹æç¤ºæ–‡ä»¶å·²ä¿å­˜åˆ°: {correction_hints_filepath}")
                except IOError as e:
                    self.signals.log_message.emit(f"è­¦å‘Š: ä¿å­˜æ ¡å¯¹æç¤ºæ–‡ä»¶å¤±è´¥: {e}")
                except Exception as e:
                    self.signals.log_message.emit(f"æœªçŸ¥é”™è¯¯ä¿å­˜æ ¡å¯¹æ–‡ä»¶: {e}")
            else:
                self.signals.log_message.emit(f"æ ¡å¯¹æç¤ºä¸ºç©ºï¼Œè·³è¿‡ç”Ÿæˆæ ¡å¯¹æ–‡ä»¶")

            if not self.is_running: self.signals.finished.emit(f"æ–‡ä»¶å·²ä¿å­˜ï¼Œä½†ä»»åŠ¡éšåè¢«å–æ¶ˆã€‚", True); return

            self.signals.progress.emit(PROGRESS_FINAL)
            self.signals.finished.emit(f"è½¬æ¢å®Œæˆï¼SRT æ–‡ä»¶å·²ä¿å­˜åˆ°:\n{output_srt_filepath}", True)

        except Exception as e:
            error_msg = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}\nè¯¦ç»†è¿½æº¯:\n{traceback.format_exc()}"
            self.signals.log_message.emit(error_msg)
            final_message = f"å¤„ç†å¤±è´¥: {e}" if self.is_running else f"ä»»åŠ¡å› ç”¨æˆ·å–æ¶ˆè€Œåœæ­¢ï¼Œè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}"
            self.signals.finished.emit(final_message, False)
        finally:
            self.is_running = False